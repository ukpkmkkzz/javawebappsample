{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKzF6dMaiLyP"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/master/assignments/assignment_yourname_t81_558_class5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDTXd8-Lmp8Q"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 5 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Your Name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNrAEpzmp8S"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "This assignment will be most straightforward if you use Google CoLab, because it requires both PyTorch and YOLOv5 to be installed. It will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU9UhAxTmp8S",
        "outputId": "25435fe0-e473-4b45-daca-99368275f434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import drive, userdata\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  COLAB = True\n",
        "  print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "  print(\"Note: not using Google CoLab\")\n",
        "  COLAB = False\n",
        "\n",
        "# Assignment Submission Key - Was sent you first week of class.\n",
        "# If you are in both classes, this is the same key.\n",
        "if COLAB:\n",
        "  # For Colab, add to your \"Secrets\" (key icon at the left)\n",
        "  key = userdata.get('T81_558_KEY')\n",
        "else:\n",
        "  # If not colab, enter your key here, or use an environment variable.\n",
        "  # (this is only an example key, use yours)\n",
        "  key = \"Gx5en9cEVvaZnjhdaushddhuhhO4PsI32sgldAXj\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSKZqD1Mmp-C"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7F2MhA7bjag8"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "from typing import List, Union\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# course - The course that you are in, currently t81-558 or t81-559.\n",
        "# no - The assignment class number, should be 1 through 10.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "\n",
        "def submit(\n",
        "    data: List[Union[pd.DataFrame, PIL.Image.Image]],\n",
        "    key: str,\n",
        "    course: str,\n",
        "    no: int,\n",
        "    source_file: str = None\n",
        ") -> None:\n",
        "    if source_file is None and '__file__' not in globals():\n",
        "        raise Exception(\"Must specify a filename when in a Jupyter notebook.\")\n",
        "    if source_file is None:\n",
        "        source_file = __file__\n",
        "\n",
        "    suffix = f'_class{no}'\n",
        "    if suffix not in source_file:\n",
        "        raise Exception(f\"{suffix} must be part of the filename.\")\n",
        "\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb', '.py']:\n",
        "        raise Exception(f\"Source file is {ext}; must be .py or .ipynb\")\n",
        "\n",
        "    with open(source_file, \"rb\") as file:\n",
        "        encoded_python = base64.b64encode(file.read()).decode('ascii')\n",
        "\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if isinstance(item, PIL.Image.Image):\n",
        "            buffered = io.BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG': base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif isinstance(item, pd.DataFrame):\n",
        "            payload.append({'CSV': base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported data type: {type(item)}\")\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://api.heatonresearch.com/wu/submit\",\n",
        "        headers={'x-api-key': key},\n",
        "        json={\n",
        "            'payload': payload,\n",
        "            'assignment': no,\n",
        "            'course': course,\n",
        "            'ext': ext,\n",
        "            'py': encoded_python\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(f\"Success: {response.text}\")\n",
        "    else:\n",
        "        print(f\"Failure: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fJKkSenqklH"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on PyTorch.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
        "\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\n",
        "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg)\n",
        "\n",
        "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bus\n",
        "\n",
        "**Do not include any counts but these three.**\n",
        "\n",
        "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
        "\n",
        "|image|bus|car|person|\n",
        "|-|-|-|-|\n",
        "|1|1|7|18|\n",
        "|2|0|7|23|\n",
        "|3|0|1|13|\n",
        "|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym5_juokofQl"
      },
      "source": [
        "### Installing YOLO\n",
        "\n",
        "YOLO is now available directly through PIP. The following commands install YOLO with PIP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuEmgV0nwGvk",
        "outputId": "9b916c64-294e-4d10-b97a-445d622ab998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.14-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.92)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu128)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu128)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.14-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.14 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOvD3M7ofQl"
      },
      "source": [
        "### Running YOLO\n",
        "\n",
        "Use this command and arguments to run YOLO, these values for iou and conf are necessary to get the same results as my solution file. I just use one image as a test, you will need to use all 10 in separate calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY3gVyidmp-K",
        "outputId": "a44468b1-98e2-475c-f108-a28c498bee57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 78.5MB/s 0.1s\n",
            "\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg to 'sidewalk1.jpg': 100% ━━━━━━━━━━━━ 69.4KB 5.3MB/s 0.0s\n",
            "image 1/1 /content/sidewalk1.jpg: 352x640 18 persons, 7 cars, 1 bus, 1 traffic light, 80.0ms\n",
            "Speed: 11.7ms preprocess, 80.0ms inference, 43.1ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "TEST_IMAGE_FILE = 'https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg'\n",
        "results = model(TEST_IMAGE_FILE,conf=0.1,iou=0.8)  # predict on an image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9jQDSkSJ6ei"
      },
      "source": [
        "You will also find the Pandas loader that we used in the course material helpful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5as8k-fhJ__a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def results_to_dataframe(results):\n",
        "    lookup = results[0].names\n",
        "    boxes = results[0].boxes\n",
        "\n",
        "    data = {\n",
        "        'class': [int(item) for item in boxes.cls],\n",
        "        'name': [lookup[int(item)] for item in boxes.cls],\n",
        "        'xmin': [int(box[0]) for box in boxes.xyxy],\n",
        "        'ymin': [int(box[1]) for box in boxes.xyxy],\n",
        "        'xmax': [int(box[2]) for box in boxes.xyxy],\n",
        "        'ymax': [int(box[3]) for box in boxes.xyxy],\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGbur-vdZWyz"
      },
      "source": [
        "I built the following function from the code presented in the course module. The function combines some of the code from the module to accept an image and return what YOLO recognizes. Make sure to use the same two thres_xxx values I provided below to match the results that I got."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCy_pvDXqYv4"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU5NCRJKzaGk",
        "outputId": "6f2335b8-5e31-4857-a7ad-43945590f4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg locally at sidewalk1.jpg\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg to 'sidewalk2.jpg': 100% ━━━━━━━━━━━━ 71.7KB 5.4MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg to 'sidewalk3.jpg': 100% ━━━━━━━━━━━━ 124.0KB 5.7MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg to 'sidewalk4.jpg': 100% ━━━━━━━━━━━━ 73.6KB 5.5MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg to 'sidewalk5.jpg': 100% ━━━━━━━━━━━━ 93.0KB 6.0MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg to 'sidewalk6.jpg': 100% ━━━━━━━━━━━━ 90.9KB 5.8MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg to 'sidewalk7.jpg': 100% ━━━━━━━━━━━━ 93.5KB 6.1MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg to 'sidewalk8.jpg': 100% ━━━━━━━━━━━━ 88.5KB 5.7MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg to 'sidewalk9.jpg': 100% ━━━━━━━━━━━━ 69.2KB 5.5MB/s 0.0s\n",
            "\u001b[KDownloading https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg to 'sidewalk10.jpg': 100% ━━━━━━━━━━━━ 50.6KB 4.8MB/s 0.0s\n",
            "   image  bus  car  person\n",
            "0      1    1    7      18\n",
            "1      2    0    7      23\n",
            "2      3    0    1      13\n",
            "3      4    0    3      35\n",
            "4      5    1    2      28\n",
            "5      6    1    4      44\n",
            "6      7    0    0      52\n",
            "7      8    0    1      49\n",
            "8      9    0    0      47\n",
            "9     10    0    0      30\n"
          ]
        }
      ],
      "source": [
        "## ... continue your code...\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "urls = [f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{i}.jpg\" for i in range(1, 11)]\n",
        "rows = []\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    results = model(url, conf=0.1, iou=0.8, verbose=False)\n",
        "    df_detected = results_to_dataframe(results)\n",
        "    counts = df_detected['name'].value_counts()\n",
        "\n",
        "    row = {\n",
        "        'image': i + 1,\n",
        "        'bus': int(counts.get('bus', 0)),\n",
        "        'car': int(counts.get('car', 0)),\n",
        "        'person': int(counts.get('person', 0))\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "submit_df = pd.DataFrame(rows)\n",
        "submit_df = submit_df[['image', 'bus', 'car', 'person']]\n",
        "print(submit_df)\n",
        "## Submit assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "SFmqHkLbYQVm",
        "outputId": "371c52d4-1bc3-4e2b-997e-14508b5ec99c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/assignment_yourname_t81_558_class5.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1404423074.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmit_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcourse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m't81-558'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2409300149.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(data, key, course, no, source_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Source file is {ext}; must be .py or .ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mencoded_python\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/assignment_yourname_t81_558_class5.ipynb'"
          ]
        }
      ],
      "source": [
        "# Add your solution here, put your results into submit_df\n",
        "\n",
        "# You must identify your source file.  (modify for your local setup)\n",
        "file=\"/content/drive/My Drive/Colab Notebooks/assignment_yourname_t81_558_class5.ipynb\"  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class5.ipynb'  # Windows\n",
        "# file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class5.ipynb'  # Mac/Linux\n",
        "\n",
        "\n",
        "submit(source_file=file,data=[submit_df],key=key,course='t81-558',no=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (torch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}